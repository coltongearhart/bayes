[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Statistics",
    "section": "",
    "text": "Overview\nThese course notes introduce the Bayesian approach to statistical inference for data analysis in a variety of applications. Topics include: comparison of Bayesian and frequentist methods, Bayesian model specification, prior elicitation, Markov chain Monte Carlo, Bayes factor, Model selection, hierarchical models, Bayesian regression models. Implementation of Bayesian data analysis will be done using R and Stan.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "Bayesian Statistics",
    "section": "Resources",
    "text": "Resources\n\nLecture notes are based on “Bayesian Data Analysis 3e” by Gelman, et al.\nGreat book also based on this book with r code examples: Bayesian inference\n\n\n\n\n\n\n\nQuarto blog publish details\n\n\n\nThis book was created using Quarto and published with Github Pages.\n\n\n\n\n\n\n\n\nGithub repository for code\n\n\n\nYou can find the code to reproduce this project at coltongearhart/bayes.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "inference.html",
    "href": "inference.html",
    "title": "\n1  Inference\n",
    "section": "",
    "text": "Notes",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "inference.html#lab",
    "href": "inference.html#lab",
    "title": "\n1  Inference\n",
    "section": "Lab",
    "text": "Lab\nSetup\nExperiment: we toss a coin 100 times and count the number of “heads” among the 100 tosses.\nNow, suppose the chance of having a “head” in such a toss is 0.50 for a particular coin. Let’s simulate the 100 tosses and analyze the outcome using Bayesian!\nThe goal of this first lab will be:\n- Become familiar with R and RStudio - Practice with vector in R - Begin to explore simulation study in R - Use computational tools to find the Bayesian point estimate and interval estimate\nStep 1 – Single experiment\nSimulate the outcomes of the 100 tosses.\n\nset.seed(1)\n\n# simulate 100 tosses of a coin individually\n# -&gt; heads = 1 and tails = 0\ndata_experiment &lt;- rbinom(n = 100, size = 1, p = 0.5)\n\nStep 2 – Response\nFind the number of “heads” and plug that into the posterior distribution of the parameter.\n\n# count the number of heads\ny &lt;- sum(data_experiment == 1)\n\n\n# alternatively we could directly simulate the number of heads out of 100\ny &lt;- rbinom(n = 1, size = 100, prob = 0.5)\n\nAs shown in the ?sec-notes-inference and in ?sec-hw-inference, \\(\\theta \\mid y \\sim \\text{Beta}(y + 1, 101 - y)\\) with prior \\(\\theta \\sim \\text{Uniform}(0,1)\\).\n\n# compare the prior distribution and the posterior distribution\nggplot() + \n  geom_line(aes(x = seq(from = 0, to = 1, by = 0.001),\n                y = dunif(seq(from = 0, to = 1, by = 0.001), min = 0, max = 1)),\n            color = \"steelblue4\") +\n  geom_line(aes(x = seq(from = 0, to = 1, by = 0.001),\n                y = dbeta(seq(from = 0, to = 1, by = 0.001), shape1 = y+1, shape2 = 101-y)),\n            color = \"orange\") + \n  annotate(\"text\",\n           x = Inf, y = Inf,\n           hjust = 1, vjust = 1,\n           label = \"Prior = Uniform(0,1)\",\n           color = \"steelblue4\") + \n  annotate(\"text\",\n           x = Inf, y = Inf,\n           hjust = 1, vjust = 3,\n           label = \"Posterior = Beta(y+1,101-y)\",\n           color = \"orange\") + \n  labs(x = expression(theta),\n       y = expression(pi(theta)))\n\n\n\n\n\n\n\nStep 3 – Frequentist point estimate\nFind the point estimate of the parameter using frequentist approach (relative frequency of the “head” among 100 tosses).\n\n# calculate frequentist point estimate p-hat = x / n\n(pe_freq &lt;- y / 100)\n\n[1] 0.48\n\n\nStep 4 – Frequentist confidence interval\nFind the 95% interval estimate of the parameter using frequentist approach (approximate z-CI of the population proportion):\n\\(\\hat{p} \\pm Z_{\\alpha/2} \\sqrt{\\frac{(\\hat{p}(1 - \\hat{p})}{n}}\\)\n\n# calculate 95% confidence interval\npe_freq + c(-1, 1) * qnorm(0.975) * sqrt(pe_freq * (1 - pe_freq) / 100)\n\n[1] 0.3820802 0.5779198\n\n\nMore choices of modified frequentist PE’s available from package binom in R.\n\n# calculate other frequentist confidence intervals\nbinom::binom.confint(x = y, n = 100, conf.level = 0.95)\n\n\n  \n\n\n\nNote that our manual calculation matches the ‘asymptotic’ interval from above.\nStep 5 – Bayes’ point estimate\nBased on the resulting posterior distribution, find the point estimate of the parameter.\nNote that \\(E(\\theta \\mid y) = \\frac{\\alpha}{\\alpha + \\beta} = \\frac{y + 1}{(y + 1) + (101 - y)} = \\frac{y + 1}{102}\\).\n\n# calculate bayes point estimate\n# -&gt; posterior mean\n(pe_bayes_mean &lt;- (y + 1) / 102)\n\n[1] 0.4803922\n\n# -&gt; posterior median\n(pe_bayes_median &lt;- qbeta(0.5, shape1 = y + 1, shape2 = 101 - y))\n\n[1] 0.4802635\n\n# -&gt; posterior mode\n# --&gt; one method\ntheta &lt;- seq(from = 0, to = 1, by = 0.001)\nd_posterior &lt;- dbeta(theta, shape1 = y + 1, shape2 = 101 - y)\nplot(x = theta, y = d_posterior, type = \"l\", xlab = expression(theta), ylab = expression(f(theta|y))) # unimodal\n\n\n\n\n\n\n(pe_bayes_mode &lt;- theta[which.max(d_posterior)])\n\n[1] 0.48\n\n# --&gt; another method\nf_x_beta &lt;- function(x, y) {\n  dbeta(x, shape1 = y + 1, shape2 = 101 - y)\n}\noptimize(f = f_x_beta, interval = c(0,1), y = y, maximum = TRUE)\n\n$maximum\n[1] 0.4799847\n\n$objective\n[1] 8.044908\n\n\nStep 6 – Bayes’ Interval\nBased on the resulting posterior distribution, find the 95% interval estimate of the parameter.\n\n# calculate bayes interval\n# -&gt; equal tails\nqbeta(p = c(0.025,0.975), shape1 = y+1, shape2 = 101-y)\n\n[1] 0.3844742 0.5770388\n\n# -&gt; HPD interval\nTeachingDemos::hpd(qbeta, shape1 = y + 1, shape2 = 101- y, conf = 0.95)\n\n[1] 0.3842179 0.5767799\n\n\nNote these don’t match the ‘bayes’ interval from binom.confint() because it is using a prior \\(\\theta \\sim \\text{Beta}(\\alpha =0.5, \\beta = 0.5)\\).\nAlso note that the HPD interval function is not a general way of finding the HPD credible intervals because it is limited to the case when we know the inverse CDF function (i.e. q&lt;dist&gt;()) of the posterior distributions and it is not always tractable.\nThe following code gives a general way of doing it, in which the “ruler” data object is basically the horizontal line segment that will be “dropped” onto the posterior density and we try to find such a “ruler” that will exactly gives HPD area of \\(1 − \\alpha\\).\nStep 7 – General HPD interval\nBelow we implement a general search procedure for finding the parameter values that correspond to the HPD interval. We just need to have the cdf of the posterior density rather than the inverse cdf like in TeachingDemos::hpd().\n\n# HPD calculation (more general approach)\n\n# specify parameter values and corresponding posterior density values (rounded to 2 decimal places so can check equality later)\ntheta &lt;- seq(from = 0, to = 1, length = 5000)\nd_posterior &lt;- dbeta(theta, shape1 = y+1, shape2= 101-y) %&gt;% round(2)\n\n# specify target -&gt; the desired coverage probability level for the interval\n# specify tolerance -&gt; variation in the desired coverage probability for the numerical search of\n# -&gt; number chosen according to the precision (decimal places) of the posterior density function values found above\ntarget &lt;- 0.95\ntol &lt;- 0.005\n\n# loop to find HPD interval\n# initialize values\n# -&gt; indicator of when search is done\n# -&gt; start counter at an index for lower bound -&gt; starting in the middle and working outwards (to find the narrowest instance in which HPD criteria is met)\ninterval_found &lt;- FALSE\ni &lt;- length(theta)/2\nwhile (i &gt; 0 & !interval_found) { # continue searching lower bounds across all parameter values or until desired interval is found\n  \n  # initialize starting index for the upper bound\n  j &lt;- length(theta)/2\n  \n  # search across parameter values for the upper bound\n  while (j &lt;= length(theta) & !interval_found){\n    \n    # check if the upper bound has an equivalent density height to the lower bound\n    if (d_posterior[i] == d_posterior[j]){\n      \n      # calculate needed values for coverage probability using cdf\n      F_lower &lt;- pbeta(theta[i], shape1 = y+1, shape2= 101-y)\n      F_upper &lt;- pbeta(theta[j], shape1 = y+1, shape2= 101-y)\n      \n      # evaluate coverage probability and check if: F(upper) - F(lower) = target +- tolerance\n      if (between(F_upper - F_lower, target - tol, target + tol)) {\n        interval_found &lt;- TRUE  \n      }\n      \n    }\n    \n    # increase upper bound\n    j &lt;- j+1\n  }\n  \n  # decrease lower bound (working inside out)\n  # -&gt; and start over with the upper bounds\n  i &lt;- i-1\n  \n}\n\n# posterior density value corresponding to the HPD region boundaries\n(k &lt;- d_posterior[i])\n\n[1] 1.3\n\n# HPD\nbound_lower_hpd &lt;- theta[i]\nbound_upper_hpd &lt;- theta[j]\npaste0(\"Index of \", target*100, \"% HPD interval boundaries: \", \"i = \", i, \" and j = \", j)\n\n[1] \"Index of 95% HPD interval boundaries: i = 1930 and j = 2875\"\n\npaste0(target*100, \"% HPD interval: [\", round(bound_lower_hpd, 3), \", \", round(bound_upper_hpd, 3), \"]\")\n\n[1] \"95% HPD interval: [0.386, 0.575]\"\n\n\nStep 8 – Simulation\nRepeat the simulation of data and analysis steps 1-6 for 50 times, record all the analysis outcomes.\n\n# define function to calculate everything (95% confidence)\n# -&gt; freq: p-hat = x / n, asymptotic interval estimates\n# -&gt; bayes: posterior mean, equal tails interval estimates\ncalc_values &lt;- function(y) {\n  \n  data.frame(y = y) %&gt;% \n    mutate(\n      pe_freq = y / 100,\n      bound_lower_freq = pe_freq - qnorm(0.975) * sqrt(pe_freq * (1 - pe_freq) / 100),\n      bound_upper_freq = pe_freq + qnorm(0.975) * sqrt(pe_freq * (1 - pe_freq) / 100),\n      pe_bayes = (y + 1) / 102,\n      bound_lower_bayes = qbeta(p = 0.025, shape1 = y+1, shape2 = 101-y),\n      bound_upper_bayes = qbeta(p = 0.975, shape1 = y+1, shape2 = 101-y)\n    )\n  \n}\n\n# simulate the number of heads many times\ny &lt;- rbinom(n = 50, size = 100, prob = 0.5)\n\n# run simulation\nresults &lt;- y %&gt;% \n  map(\\(y_i) calc_values(y_i)) %&gt;% \n  reduce(bind_rows) %&gt;% \n  mutate(i = row_number(),\n         .before = 1)\nresults %&gt;% round(3) %&gt;% head",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "inference.html#homework",
    "href": "inference.html#homework",
    "title": "\n1  Inference\n",
    "section": "Homework",
    "text": "Homework\nSetup\nExperiment: we toss a coin 100 times and count the number of “heads” among the 100 tosses.\nNow, suppose the coin we use is very biased, and the chance of having a “head” in such a toss is 0.05. Please simulate the experiment of 100 tosses with this coin for 1000 times and analyze the outcome using Bayesian.\nPart a – Experiment\nDraw a boxplot of the 1000 different experiment outcomes; does this plot match what you expected? Why or why not?\n\nset.seed(1)\n\n# simulate coin 100 coin tosses 1000 times\np &lt;- 0.05\nn &lt;- 100\nm &lt;- 1000\ndata_results &lt;- rbinom(n = m, size = n, prob = p) %&gt;% \n  data.frame(y = .)\n\n# draw boxplot of results\nboxplot(data_results$y, main = \"Number of heads\", horizontal = TRUE)\n\n\n\n\n\n\n\nThe boxplot is more or less what I expected, the median is very close the the expected number of heads out of 100 tosses. Perhaps expected it to be more right skewed because the true population proportion is so small.\nPart b – Frequentist confidence interval\nFind the 95% interval estimates of the parameter using frequentist approach with each of the 1000 simulated experiment (approximate z-CI of the population proportion):\n\\(\\hat{p} \\pm Z_{\\alpha/2} \\sqrt{\\frac{(\\hat{p}(1 - \\hat{p})}{n}}\\)\nAmong the 1000 simulations, what is the proportion of CIs including the true proportion p = 0.05? Calculate the average width of the 1000 CIs.\n\n# define function to calculate margin of error\ncalc_moe &lt;- function(p_hat, n, c) {\n  qnorm((1 - c) / 2, lower.tail = FALSE) * sqrt(p_hat * (1 - p_hat) / n)\n}\n\n# calculate 95% frequentist confidence interval\nc &lt;- 0.95\ndata_results %&lt;&gt;% \n  mutate(p_hat = y / n,\n         bound_lower = p_hat - calc_moe(p_hat, n, c),\n         bound_upper = p_hat + calc_moe(p_hat, n, c),\n         capture = bound_lower &lt; p & bound_upper &gt; p)\n\n# display first few CIs\ndata_results %&gt;% display_nice(n = 5)\n\n\n\n y \n    p_hat \n    bound_lower \n    bound_upper \n    capture \n  \n\n\n 4 \n    0.04 \n    0.002 \n    0.078 \n    TRUE \n  \n\n 4 \n    0.04 \n    0.002 \n    0.078 \n    TRUE \n  \n\n 5 \n    0.05 \n    0.007 \n    0.093 \n    TRUE \n  \n\n 8 \n    0.08 \n    0.027 \n    0.133 \n    TRUE \n  \n\n 3 \n    0.03 \n    -0.003 \n    0.063 \n    TRUE \n  \n\n\n\n# nest results\ndata_results %&lt;&gt;% \n  mutate(i = row_number(),\n         .before = y) %&gt;% \n  nest(ci_freq = c(p_hat, bound_lower, bound_upper, capture))\nhead(data_results, n = 5)\n\n\n  \n\n\n# calculate capture rate\ndata_results$ci_freq %&gt;% \n  reduce(bind_rows) %&gt;% \n  summarize(avg_width = mean(bound_upper - bound_lower),\n            capture_rate = mean(capture))\n\n\n  \n\n\n\nPart c – Bayesian interval\nBased on the resulting posterior distribution, find the 95% Bayesian interval estimates (use equal tail) of the parameter using a uniform (0, 1) prior of the parameter for each of the 1000 simulated experiment; Among the 1000 simulations, what is the proportion of CIs including the true proportion p = 0.05? Calculate the average width of the 1000 CIs.\nDerivation of posterior distributions. Additionally includes the posterior mean as the theoretical point estimate.\n\n\n# calculate point estimate (posterior mean) and 95% equal tails interval\n# -&gt; using uniform(0,1) = beta(1,1) prior\nalpha &lt;- 1\nbeta &lt;- 1\ndata_results %&lt;&gt;% mutate(post_mean = (y + 1) / (n + alpha + beta),\n                         bound_lower = qbeta((1 - c)/2, shape1 = y + alpha, shape2 = (n + beta) - y),\n                         bound_upper = qbeta(1 - (1 - c)/2, shape1 = y + alpha, shape2 = (n + beta) - y),\n                         capture = bound_lower &lt; p & bound_upper &gt; p)\n\n# display first few CIs\ndata_results %&gt;% \n  select(-ci_freq) %&gt;% \n  display_nice(n = 5)\n\n\n\n i \n    y \n    post_mean \n    bound_lower \n    bound_upper \n    capture \n  \n\n\n 1 \n    4 \n    0.049 \n    0.016 \n    0.098 \n    TRUE \n  \n\n 2 \n    4 \n    0.049 \n    0.016 \n    0.098 \n    TRUE \n  \n\n 3 \n    5 \n    0.059 \n    0.022 \n    0.112 \n    TRUE \n  \n\n 4 \n    8 \n    0.088 \n    0.042 \n    0.150 \n    TRUE \n  \n\n 5 \n    3 \n    0.039 \n    0.011 \n    0.084 \n    TRUE \n  \n\n\n\n# nest results\ndata_results %&lt;&gt;% \n  nest(ci_bayes_uniform = c(post_mean, bound_lower, bound_upper, capture))\nhead(data_results, n = 5)\n\n\n  \n\n\n# calculate capture rate\ndata_results$ci_bayes_uniform %&gt;% \n  reduce(bind_rows) %&gt;% \n  summarize(avg_width = mean(bound_upper - bound_lower),\n            capture_rate = mean(capture))\n\n\n  \n\n\n\nPart d – Comparison\nCompare your results in parts b and c, how similar are they? How different are they?\nAverage width of the frequentist interval is smaller than that of the equal tails Bayes interval, which implies the capture rate should be higher for the latter. However it is quite a bit higher.\nPart e – New prior\nRepeat part d using a Beta(1, 10) prior of the parameter \\(p\\).\n\n\n# calculate point estimate (posterior mean) and 95% HPD interval\n# -&gt; using beta(1,10)\nalpha &lt;- 1\nbeta &lt;- 10\ndata_results %&lt;&gt;% mutate(post_mean = (y + 1) / (n + alpha + beta))\n# TeachingDemos::hpd() not working in mutate()\ndata_results$bound_lower &lt;- data_results$y %&gt;% map(function(y) {\n  TeachingDemos::hpd(qbeta, shape1 = y + alpha, shape2 = (n + beta) - y, conf = 0.95)[1]\n})\ndata_results$bound_upper &lt;- data_results$y %&gt;% map(function(y) {\n  TeachingDemos::hpd(qbeta, shape1 = y + alpha, shape2 = (n + beta) - y, conf = 0.95)[2]\n})\ndata_results %&lt;&gt;% mutate(across(c(bound_lower, bound_upper), as.double), # simplify result type\n                         capture = bound_lower &lt; p & bound_upper &gt; p)\n\n# display first few CIs\ndata_results %&gt;% \n  select(-c(ci_freq, ci_bayes_uniform)) %&gt;% \n  display_nice(n = 5)\n\n\n\n i \n    y \n    post_mean \n    bound_lower \n    bound_upper \n    capture \n  \n\n\n 1 \n    4 \n    0.045 \n    0.011 \n    0.084 \n    TRUE \n  \n\n 2 \n    4 \n    0.045 \n    0.011 \n    0.084 \n    TRUE \n  \n\n 3 \n    5 \n    0.054 \n    0.017 \n    0.096 \n    TRUE \n  \n\n 4 \n    8 \n    0.081 \n    0.034 \n    0.132 \n    TRUE \n  \n\n 5 \n    3 \n    0.036 \n    0.007 \n    0.071 \n    TRUE \n  \n\n\n\n# nest results\ndata_results %&lt;&gt;% \n  nest(ci_bayes_beta = c(post_mean, bound_lower, bound_upper, capture))\nhead(data_results, n = 5)\n\n\n  \n\n\n# calculate capture rate\ndata_results$ci_bayes_beta %&gt;% \n  reduce(bind_rows) %&gt;% \n  summarize(avg_width = mean(bound_upper - bound_lower),\n            capture_rate = mean(capture))\n\n\n  \n\n\n\nPart f – Final comparison\nCompare your results in parts b, c and e. How different are they? How similar are they? Why would you see these differences?\n\n# display all summaries at same time\ndata_results %&gt;% \n  select(starts_with(\"ci\")) %&gt;% \n  map(\\(col) reduce(col, bind_rows)) %&gt;% \n  map2(c(\"freq\", \"bayes_uniform\", \"bayes_beta\"),\n       \\(df, nm) summarize(df, avg_width = mean(bound_upper - bound_lower) %&gt;% round(3),\n                            capture_rate = mean(capture)) %&gt;% \n         mutate(method = nm,\n                .before = 1)) %&gt;% \n  reduce(bind_rows)\n\n\n  \n\n\n\nBayes beta(10,1) resulted in the smallest intervals on average, which makes sense because the prior distribution incorporated good knowledge of the true population proportion. It also had a capture rate almost as high as the, on average, wider confidence intervals from the Bayes with uniform prior.\nPart g – Additional insightful plots\nComparison of priors.\n\n# compare different prior distributions for the Bayesian credible intervals\nggplot() + \n  geom_line(aes(x = seq(from = 0, to = 1, by = 0.001),\n                y = dunif(seq(from = 0, to = 1, by = 0.001), min = 0, max = 1)),\n            color = \"green\") +\n  geom_line(aes(x = seq(from = 0, to = 1, by = 0.001),\n                y = dbeta(seq(from = 0, to = 1, by = 0.001), shape1 = 1, shape2 = 10)),\n            color = \"blue\") + \n  annotate(\"text\",\n           x = Inf, y = Inf,\n           hjust = 1, vjust = 1,\n           label = \"Uniform(0,1)\",\n           color = \"green\") + \n  annotate(\"text\",\n           x = Inf, y = Inf,\n           hjust = 1, vjust = 3,\n           label = \"Beta(1,10)\",\n           color = \"blue\") + \n  labs(title = \"Prior distributions\",\n       x = expression(theta),\n       y = expression(pi(theta)))\n\n\n\n\n\n\n\nComparison of point estimates (\\(\\hat{p}\\) for frequentist and \\(E(\\theta \\mid y)\\) for Bayes).\n\n# comparative boxplots of point estiamtes\ndata_results %&gt;% \n  select(starts_with(\"ci\")) %&gt;% \n  map(\\(col) reduce(col, bind_rows)) %&gt;% \n  map2(c(\"freq\", \"bayes_uniform\", \"bayes_beta\"),\n       \\(df, nm) select(df, pe = 1) %&gt;% # select and rename point estimate\n         mutate(method = nm,\n                .before = 1)) %&gt;% \n  reduce(bind_rows) %&gt;% \n  ggplot(aes(x = pe, y = method)) + \n  geom_boxplot() + \n  geom_vline(xintercept = p,\n             col = \"blue\") + \n  annotate(\"text\",\n           x = Inf, y = -Inf,\n           hjust = 1, vjust = -1, \n           label = \"true parameter\",\n           color = \"blue\") + \n  labs(x = \"Point estimate\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inference</span>"
    ]
  },
  {
    "objectID": "single-parameter-inference.html",
    "href": "single-parameter-inference.html",
    "title": "\n2  Single parameter inference\n",
    "section": "",
    "text": "Lab",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Single parameter inference</span>"
    ]
  },
  {
    "objectID": "single-parameter-inference.html#lab",
    "href": "single-parameter-inference.html#lab",
    "title": "\n2  Single parameter inference\n",
    "section": "",
    "text": "Setup\nLet’s revisit the coin toss example today. We will work on it with multiple approaches. This time, let’s just assume we tossed the coin 100 times and get 50 (\\(Y = 50\\)) heads.\n\nData distribution: \\(Y \\mid p \\sim Bin(100, p)\\)\n\nPrior: \\(p \\sim \\text{Uniform}(0,1)\\)\n\nObserved data: \\(y = 50\\)\n\nStep 1 – Estimation of parameters using known posterior distribution\nIf we know the math and used integration to find the posterior:\n\nPosterior: \\(p \\mid y = 50 \\sim \\text{Beta}(51, 51)\\)\n\nSimulate the outcomes of the 100 tosses.\n\n\n# shape of the posterior distribution\ncurve(dbeta(x, shape1 = 51, shape2 = 51), from = 0, to = 1)\n\n\n\n\n\n\n\n\n# point estimates\n(posterior_mean &lt;- 51 / 102)\n\n[1] 0.5\n\n(posterior_median &lt;- qbeta(p = 0.50, shape1 = 51, shape2 = 51))\n\n[1] 0.5\n\nx &lt;- seq(from = 0, to = 1, length = 300)\nd_posterior &lt;- dbeta(x, shape1 = 51, shape2 = 51)\n(posterior_mode &lt;- x[which.max(d_posterior)])\n\n[1] 0.4983278\n\n\n\n# credible intervals\n\n# quantile based 95% confidence interval \nqbeta(p = c(0.025,0.975), shape1 = 51, shape2 = 51)\n\n[1] 0.4036431 0.5963569\n\n# 95% HPD CI\nTeachingDemos::hpd(qbeta, shape1 = 51, shape2 = 51, conf = 0.95)\n\n[1] 0.4036431 0.5963569\n\n\nStep 2 – Estimation of parameters using simulation\nSimulation is commonly used when the posterior doesn’t have an explicit form. This process is illustrated below (although this one does have a closed form solution that we can use to validate the results).\n\nNote that we can always write down the posterior distribution because it is just the product of the data distribution and the prior (which we always know / assume), but often the explicit for of the posterior is not a known form (e.g. \\(\\sim \\text{Beta}\\) or \\(\\sim \\text{Normal}\\).\n\nIf we do not know the math, we can still find the posterior, but we won’t have the exact posterior distribution, instead we are able to generate posterior samples. This is easy to implement and use when we have a simple model and single parameter.\n\n\nFirstly, we create a sequence of possible values of the parameter (discretize the parameter space of \\(p\\)).\n\nNote that the method of discretizing the parameter space is not a very good method in practice and it cannot be used when the parameter space is unbounded.\n\n\n\nSecondly, we construct the prior density values for each of the possible values and using Bayes Theorem, we combine the prior density and likelihood function into the posterior.\n\nNote that we would numerically sum the products of prior density and likelihood values to find the normalizing constant \\(p(y)\\).\n\n\nThirdly, simulate random draws from the approximate posterior distribution.\n\n\n\n# 1) create a sequence of possible values for the parameter\np &lt;- seq(from = 0.001, to = 0.999, by = 0.001)\n\n# 2) construct the posterior, assuming y = 50 is observed\n# =&gt; posterior = data dist * prior dist\n# -&gt; getting the functional value at each p\nf_p_post &lt;- dbinom(x = 50, size = 100, prob = p) * dunif(p)\n\n# 3) simulate p from the posterior distribution\n# -&gt; randomly sample according to weights\nn_sim &lt;- 100000\np_post &lt;- sample(x = p, size = n_sim, replace = TRUE, prob = f_p_post)\n\n# view approximate distribution\nhist(p_post)\n\n\n\n\n\n\n\n\n# point estimates\n(posterior_mean_sim &lt;- mean(p_post))\n\n[1] 0.4998633\n\n(posterior_median_sim &lt;- median(p_post))\n\n[1] 0.5\n\n(posterior_mode_sim &lt;- p[which.max(f_p_post)])\n\n[1] 0.5\n\n\n\n# credible interval\n# -&gt; quantile based 95% confidence interval \nquantile(p_post, c(0.025, 0.975))\n\n 2.5% 97.5% \n0.403 0.596 \n\n\nStep 3 – Simulation-based prediction of future observations\nYou certainly can predict your future observations based on the posterior predictive distribution by doing the math here. But it is often difficult to analytically solve with calculus. On the opposite, it is fairly easy to get the posterior predictive distribution using simulation.\nNote that we have simulated \\(p\\) from the posterior distribution and saved them in the vector p_post, so let’s directly use them and simulate the future observation conditional on each one of these \\(p\\)’s to get an idea of the posterior predictive distribution.\n\n\np_post can also be simulated directly from \\(\\text{Beta}(51, 51)\\) (the posterior distribution shown in @notes-inference) via p_post = rbeta(nsim, 51,51). But the process described above is an approximation of simulating from this.\n\nOne toss: We already analytically figured out the posterior predictive distribution of 1 additional coin toss in class, so now we can numerically compare ̃the simulation vs analytical answer (\\(P(\\tilde{Y} = 1 \\mid Y = 50) = 0.5\\)):\n\n# generate an experimental value of the coin toss for each of the n_sim = 100,000 values of p from the posterior distribution\n# -&gt; need to make sure that the number of predicted responses should match the number of posterior samples of the parameter!\ny_pred_post_1_sim &lt;- rbinom(n = n_sim, size = 1, prob = p_post)\n\n# summarize the posterior predictive distribution\n# -&gt; frequency table of the future observations table\ntable(y_pred_post_1_sim)\n\ny_pred_post_1_sim\n    0     1 \n50066 49934 \n\n# calculate the naive posterior predictive distribution table using relative frequency\ntable(y_pred_post_1_sim) / length(y_pred_post_1_sim)\n\ny_pred_post_1_sim\n      0       1 \n0.50066 0.49934 \n\n\n5 tosses: Now let’s assume that we plan to toss the coin for another 5 times.\n\n# same as above, except for 5 tosses\ny_pred_post_5_sim &lt;- rbinom(n = n_sim, size = 5, prob = p_post)\ntable(y_pred_post_5_sim)\n\ny_pred_post_5_sim\n    0     1     2     3     4     5 \n 3258 15839 30629 30650 16198  3426 \n\ntable(y_pred_post_5_sim) / length(y_pred_post_5_sim)\n\ny_pred_post_5_sim\n      0       1       2       3       4       5 \n0.03258 0.15839 0.30629 0.30650 0.16198 0.03426 \n\n\n\n\n# calculate analytical result\n# -&gt; y-pred_post | y-vec = 101! (50 + y-tilde)! (55 - y-tilde)! 5! / (50! 50! 106! y-tilde! (5 - y-tilde)!)\ny_pred_post_5 &lt;- function(y) {\n  factorial(101) * factorial(50+y) * factorial(55-y) *  factorial(5) / (factorial(50) * factorial(50) * factorial(106) * factorial(y) * factorial(5-y))\n}\n\n# calculate probabilities for each possible y-tilde value (number of successes out of 5 tosses)\nsapply(0:5, y_pred_post_5)\n\n[1] 0.03432732 0.15915395 0.30651872 0.30651872 0.15915395 0.03432732\n\n\n100 tosses: Let’s assume that we plan to toss the coin for another 100 times first.\n\n# same as above, except for 100 tosses\ny_pred_post_100_sim &lt;- rbinom(n = n_sim, size = 100, prob = p_post)\n\n# create pmf plot\n# -&gt; sort predicted values to match order returned from table()\nplot(x = y_pred_post_100_sim %&gt;% unique %&gt;% sort,\n     y = y_pred_post_100_sim %&gt;% table %&gt;% as.numeric %&gt;% divide_by(n_sim),\n     type = \"h\", xlab = \"Y-pred\", ylab = \"freq\")\n\n\n\n\n\n\n\n\n# calculate analytical result\n# -&gt; (not simplifying to factorials) y-pred_post | y-vec = C(100,y-tilde) beta(51 + y-tilde, 51 - y-tilde) / beta(51, 51)\n\ny_pred_post_100 &lt;- function(y) {\n\n  choose(100,y) * beta(51+y,151-y)/beta(51,51)\n\n}\n\n# calculate probabilities for each possible y-tilde value (number of successes out of 100 tosses)\nsapply(0:100, y_pred_post_100)\n\n  [1] 1.117015e-19 3.797850e-18 6.560849e-17 7.675012e-16 6.837026e-15\n  [6] 4.945136e-14 3.023922e-13 1.607359e-12 7.578753e-12 3.218894e-11\n [11] 1.246465e-10 4.443569e-10 1.470001e-09 4.542745e-09 1.318770e-08\n [16] 3.613687e-08 9.385549e-08 2.318783e-07 5.466671e-07 1.233270e-06\n [21] 2.668948e-06 5.552976e-06 1.112943e-05 2.152547e-05 4.024020e-05\n [26] 7.281560e-05 1.277074e-04 2.173466e-04 3.593414e-04 5.777088e-04\n [31] 9.039631e-04 1.377815e-03 2.047184e-03 2.967207e-03 4.197949e-03\n [36] 5.800615e-03 7.832231e-03 1.033899e-02 1.334871e-02 1.686314e-02\n [41] 2.085104e-02 2.524317e-02 2.993008e-02 3.476375e-02 3.956334e-02\n [46] 4.412515e-02 4.823618e-02 5.169008e-02 5.430386e-02 5.593363e-02\n [51] 5.648743e-02 5.593363e-02 5.430386e-02 5.169008e-02 4.823618e-02\n [56] 4.412515e-02 3.956334e-02 3.476375e-02 2.993008e-02 2.524317e-02\n [61] 2.085104e-02 1.686314e-02 1.334871e-02 1.033899e-02 7.832231e-03\n [66] 5.800615e-03 4.197949e-03 2.967207e-03 2.047184e-03 1.377815e-03\n [71] 9.039631e-04 5.777088e-04 3.593414e-04 2.173466e-04 1.277074e-04\n [76] 7.281560e-05 4.024020e-05 2.152547e-05 1.112943e-05 5.552976e-06\n [81] 2.668948e-06 1.233270e-06 5.466671e-07 2.318783e-07 9.385549e-08\n [86] 3.613687e-08 1.318770e-08 4.542745e-09 1.470001e-09 4.443569e-10\n [91] 1.246465e-10 3.218894e-11 7.578753e-12 1.607359e-12 3.023922e-13\n [96] 4.945136e-14 6.837026e-15 7.675012e-16 6.560849e-17 3.797850e-18\n[101] 1.117015e-19\n\n# compare to simulated results\n# -&gt; get the theoretical functional values for the unique simulated posterior predictive values\nplot(x = y_pred_post_100_sim %&gt;% unique %&gt;% sort %&gt;% sapply(y_pred_post_100),\n     y = y_pred_post_100_sim %&gt;% table %&gt;% as.numeric %&gt;% divide_by(n_sim), \n     xlab = \"analytical\", ylab = \"simulated\")\nabline(0,1)\n\n\n\n\n\n\n\n\n# point estimation/prediction for the future observations\nmean(y_pred_post_100_sim)\n\n[1] 50.00057\n\n# prediction interval\nquantile(y_pred_post_100_sim, c(0.025,0.975))\n\n 2.5% 97.5% \n   36    64 \n\n\nCompare the posterior predictive samples vs the prior predictive samples. First we need to simulate \\(p\\) from the prior distribution, then simulate the future observation conditional on each one of these \\(p\\)’s to get an idea of the prior predictive distribution.\n\n# generate an experimental value of the future 100 tosses for each p\np_prior &lt;- sample(x = p, size = n_sim, replace = TRUE, prob = dunif(p))\ny_pred_prior_100_sim &lt;- rbinom(n = n_sim, size = 100, prob = p_prior)\n\n# calculate point estimate and interval\nmean(y_pred_prior_100_sim)\n\n[1] 49.91446\n\nquantile(y_pred_prior_100_sim, c(.025,.975))\n\n 2.5% 97.5% \n    2    98 \n\n\n\n# compare with what we got earlier:\n\n# compare the two distribution via density curves \nplot(density(y_pred_post_100_sim), xlim = c(0,100), main = \"Prior/posterior pred. dist. of 100 future tosses\")\nlines(density(y_pred_prior_100_sim),col = \"red\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Single parameter inference</span>"
    ]
  },
  {
    "objectID": "single-parameter-inference.html#homework",
    "href": "single-parameter-inference.html#homework",
    "title": "\n2  Single parameter inference\n",
    "section": "Homework",
    "text": "Homework\nPICTURES AND RELOCATE\n\nProblem 1\nThirty randomly selected Chase customers in Cincinnati were interviewed about their experiences with Chase financial investment advising service back in 2016 and they reported the average waiting time (unit: days) until the first meeting with a financial advisor in their local branch (given below). Julia, the Chase marketing manager believes that these waiting times can be reasonably modeled with an exponential distribution, i.e., \\(Y_1, \\ldots, Y_{30} \\overset{iid}\\sim \\text{Exp}(\\lambda)\\), or \\(f(y_i \\mid \\lambda) = \\lambda\\mathrm{e}^{-\\lambda y_i}\\), where \\(i = 1, \\ldots, 30\\).\n\ny &lt;- c(4.3,1.0,0.5,5.2,2.5,1.6,1.3,2.5,1.2,2.3,0.8,14.4,1.7,0.5,2.2,\n        4.5,2.7,1.2,5.5,2.6,0.2,0.6,2.1,0.6,1.9,3.8,1.1,5.2,2.1,2.0)\n\nPart a – Prior distribution\nJulia considered a Bayesian analysis. From the historical data, on average the bank customers waited 2.5 days until their first meeting with the bank financial advisor. She assumed that the prior variance is 0.2. Please use this information to obtain an informative prior distribution for \\(\\lambda\\).\nPart b – Posterior distribution\nUse the prior in (a), find the posterior distribution for \\(\\lambda\\).\n\n# needed calculation for posterior gamma(alpha, beta)\n# -&gt; beta-post = beta-prior + sum(y)\n12.5 + sum(y)\n\n[1] 90.6\n\n\nProblem 2\nProgesterone level is monitored for 30 randomly chosen pregnant sheep with singletons that are 80 days pregnant.\n\ny &lt;- c(3.8,5.0,4.5,4.2,5.5,5.8,4.6,5.3,7.2,5.7,6.0,6.3,4.8,5.6,4.9,\n       4.3,4.9,4.2,3.4,4.8,5.2,5.9,5.7,2.8,6.6,6.1,9.3,7.7,5.3,7.8)\n\nJeff would like to model these measurements as normal responses from the same normal population, \\(\\text{N}(\\mu,1.52)\\). He also found out in literature that, for 80-days pregnant sheep with singletons, the average progesterone level should be centered around 8, and the range of such measurements is between 4 and 12.\nPart a – Prior distribution\nPlease suggest a prior distribution of μ for Jeff based on the literature information.\nPart b – Posterior distribution\nSpecify the posterior distribution parameters of \\(\\mu\\).\n\n# specify parameters, hyperparameters and other needed constants\nsigma &lt;- 1.5\nmu_0 &lt;- 8\ntau_0 &lt;- 4/3\nn &lt;- length(y)\n\n# calculate posterior parameters\n(tau2_n &lt;- (n / sigma^2 + 1 / tau_0^2)^(-1))\n\n[1] 0.07196402\n\n(mu_n &lt;- tau2_n * (sum(y) / sigma^2 + mu_0 / tau_0^2))\n\n[1] 5.543628\n\n\nPart c – Monte Carlo probability\nUse the Monte Carlo approach to calculate \\(P(\\mu &gt; 5 \\mid \\mathbf{y})\\).\n\n# generate sample from posterior distribution\n# -&gt; mu | y-vec ~ Normal(mu_n, tau^2_n)\nmu_post_sample &lt;- rnorm(n = 10000, mean = mu_n, sd = sqrt(tau2_n))\nhead(mu_post_sample, n = 5)\n\n[1] 5.571097 5.111287 5.813738 5.832293 5.745582\n\n# calculate Monte Carlo probability\n# -&gt; P(mu &gt; 5 | y-vec)\n(prob &lt;- mean(mu_post_sample &gt; 5))\n\n[1] 0.9776\n\n\nUsing Monte Carlo methods, our estimate of \\(P(\\mu &gt; 5 \\mid \\mathbf{y}) \\approx\\) 0.978\nPart d – Posterior predictive distribution\nA new sheep will be selected at random from the same population of interest. Simulate the posterior predictive distribution of the progesterone level of this new sheep. Report the estimated mean and standard deviation of the progesterone level for this new sheep based on the posterior predictive distribution you obtain.\nSimulation approach\n\n# simulate posterior predictive distribution\n\n# simulate mu's from posterior mu | y-vec\nM &lt;- 10000\nmu_m &lt;- rnorm(n = M, mean = mu_n, sd = sqrt(tau2_n))\nhead(mu_m)\n\n[1] 6.031685 5.167160 5.354220 5.721532 5.207288 5.485899\n\n# simulate new observations from data distribution using newly sampled mu's\ny_new &lt;- rnorm(n = M, mean = mu_m, sd = sigma)\nhead(y_new)\n\n[1] 5.637289 7.263881 5.798234 3.562319 4.900930 4.733504\n\n# approximate mean and standard deviation of posterior predictive distribution\nmean(y_new) \n\n[1] 5.568709\n\nvar(y_new)\n\n[1] 2.302108\n\n\nVerify with known theoretical results.\nBased on the derivations in ?sec-notes-single-parameter-inference (part 3), for the normal model with unknown mean and known variance, the posterior predictive distribution \\(\\tilde{Y} \\sim \\text{Normal}(\\mu_n, \\sigma^2 + \\tau^2_n)\\).\n\n# sample directly from the known posterior predictive distribution\ny_new_theory &lt;- rnorm(n = M, mean = mu_n, sd = sqrt(sigma^2 + tau2_n))\n\n# compare simulated posterior predictive sample and that of the theoretical\n# -&gt; line up perfectly\ndata.frame(y_new = y_new, dist = \"simulated\") %&gt;% \n  bind_rows(data.frame(y_new = y_new_theory, dist = \"theoretical\")) %&gt;% \n  ggplot(aes(x = y_new,\n             color = dist)) + \n  geom_density() + \n  labs(x = expression(tilde(y)))\n\n\n\n\n\n\n\nProblem 3\nJill is the data analyst at the Tristate Phoenix clinic, she randomly selected records of the BMI from female patients in the clinic (denoted by \\(X_1, \\ldots, X_{32}\\)) and male patients (denoted by \\(Y_1, \\ldots, Y_{28}\\)), and she assumed these two sets of records were independent normally distributed with means \\(\\mu_X, \\mu_Y\\) , and variances \\(\\sigma^2_X = \\sigma^2_Y = 1\\). Could you help her calculate a 95% credible interval (equal tails) for \\(\\mu_X − \\mu_Y\\), using the following priors \\(\\mu_X \\sim \\text{N}(\\mu = 22, \\sigma^2 = 4),\\, \\mu_Y \\sim \\text{N}(\\mu = 20.5, \\sigma^2 = 4)\\) on \\(\\mu_X, \\mu_Y\\)?\n\nx = c(22.7,21.5,23.1,21.7,23.2,22.4,20.3,23.7,23.2,22.3,24.3,\n      22.3,22.9,22.1,22.3,21.2,23.5,21.5,21.6,20.9,20.0,20.0,\n      21.1,24.1,22.6,22.2,21.3,20.8,22.0,22.9,23.2,20.5)\n\ny = c(22.0,20.3,20.6,20.4,20.5,20.0,18.9,20.2,21.4,21.4,18.5,20.8,22.8,19.1,\n      18.8,19.7,21.0,20.2,21.3,20.5,19.2,20.6,20.1,18.9,20.9,19.6,21.3,21.4)\n\n\n# simulate mu_X - mu_Y from the posterior distribution\n\nProblem 4\nSuppose \\(Y \\mid \\theta \\sim \\text{Poisson}(\\theta)\\). Find the Jeffrey’s prior for \\(\\theta\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Single parameter inference</span>"
    ]
  }
]